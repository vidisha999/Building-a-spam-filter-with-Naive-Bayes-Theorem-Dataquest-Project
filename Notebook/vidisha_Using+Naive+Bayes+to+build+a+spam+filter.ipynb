{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a spam filter with Naive Bayes Theorem\n",
    "\n",
    "The goal of his project tio build a spam filter using the multinomial Naive Bayes algorithm. It learsn how human classify the messages and uses that human knowledge to estimate probabilities for new messages by calculating the probabillities for both spam and non spam messages. Then based on the probability values, if the probability of the spam messages is higher than that of the non-spam messages, it classifies the new message as a spam message.This classification task is performed on the dataset of 5,572 messages extracted from UCI Machine Learning Repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "sms=pd.read_csv('SMSSpamCollection',sep='\\t',header=None,names=['Label',\"SMS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the datasest: {(5572, 2)}\n",
      "ham     86.593683\n",
      "spam    13.406317\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "shape=sms.shape\n",
    "print('shape of the datasest:',{shape})\n",
    "unique_labels=sms['Label'].value_counts(normalize=True)*100\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 5,572 messages. Out of them, 86.59% are non-spam messages while rest of 13.41% are identified as spam messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "sms_cp=sms.sample(frac=1,random_state=1) # randomize the entire datasest\n",
    "\n",
    "# Using the manual method to split the data to test and trainig sets\n",
    "data_index = round(len(sms_cp) * 0.8)\n",
    "\n",
    "# Training/Test split\n",
    "training_set = sms_cp[:data_index].reset_index(drop=True)\n",
    "test_set = sms_cp[data_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(training_set['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test_set['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the percentages of spam and non-spam messages in both training and test datasets above, the values corresponds with the percentages of the each label in the full dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Using the sklearn's train_test_split to split dataset\\nX=sms_cp['SMS']\\ny=sms_cp['Label']\\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=72)\\ntraining_labels= y_train.value_counts(normalize=True)*100\\ntest_labels=y_test.value_counts(normalize=True)*100\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Using the sklearn's train_test_split to split dataset\n",
    "X=sms_cp['SMS']\n",
    "y=sms_cp['Label']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=72)\n",
    "training_labels= y_train.value_counts(normalize=True)*100\n",
    "test_labels=y_test.value_counts(normalize=True)*100'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Each letter in the sms messages should be cleaned and transformed in to a standard format which makes the clasification task for each word in the message easier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing the punctuation marks with a space using the regex '\\w'\n",
    "training_set['SMS']=training_set['SMS'].str.replace('\\W',' ')\n",
    "\n",
    "#Transforming the words to lowercase letters\n",
    "training_set['SMS']=training_set['SMS'].str.lower()\n",
    "\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary\n",
    "\n",
    "creating a vocabulary which is a list containinig all unique words across all messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set['SMS']=training_set['SMS'].str.split() #splitting string at space character\n",
    "\n",
    "vocabulary=[]\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "vocabulary=list(set(vocabulary)) # ELiminated duplicate by transforming to a set and retransformed back to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a dictionary with the unique word count and transform the dictionary to the format of the DataFrame which is necessary for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms={unique_word:[0]*len(training_set['SMS']) for unique_word in vocabulary} # initialize the empty dictionary \n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "\n",
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating constants to apply the Naive Bayes Theorem \n",
    "\n",
    "P(Spam|w1,w2,...,wn)∝**P(Spam)**⋅n∏i=1 **P(wi|Spam)**\n",
    "\n",
    "P(Ham|w1,w2,...,wn)∝**P(Ham)**⋅n∏i=1  **P(wi|Ham)**\n",
    "\n",
    "**P(wi|Spam)**=Nwi|Spam+α/(NSpam+α⋅NVocabulary)\n",
    "\n",
    "**P(wi|Ham)**=Nwi|Ham+α /(NHam+α⋅NVocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Isolating spam and ham messages \n",
    "training_spam=training_set_clean[training_set_clean['Label']=='spam']\n",
    "training_ham=training_set_clean[training_set_clean['Label']=='ham']\n",
    "\n",
    "N_spam=training_spam['SMS'].apply(len).sum()\n",
    "N_ham=training_ham['SMS'].apply(len).sum()\n",
    "\n",
    "N_vocabulary= len(vocabulary)\n",
    "\n",
    "\n",
    "alpha = 1 # Laplace smoothing\n",
    "\n",
    "p_spam=len(training_spam)/len(training_set_clean)\n",
    "p_ham=len(training_ham)/len(training_set_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# calculate parameters \n",
    "\n",
    "for word in vocabulary:\n",
    "    N_word_given_spam=training_spam[word].sum()\n",
    "    P_word_given_spam=(N_word_given_spam*alpha)/(N_spam+alpha*N_vocabulary)\n",
    "    parameters_spam[word]=P_word_given_spam\n",
    "    \n",
    "    N_word_given_ham=training_ham[word].sum()\n",
    "    P_word_given_ham=(N_word_given_ham*alpha)/(N_ham+alpha*N_vocabulary)\n",
    "    parameters_ham[word]=P_word_given_ham\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying a new message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 8.100463856544482e-26\n",
      "P(Ham|message): 0.0\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 0.0\n",
      "P(Ham|message): 2.1950292848845383e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meassure spam filter's accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the classification functin to test on the test dataset and return the label as 'spam' or 'ham' for each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):    \n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham          Later i guess. I needa do mcat study too.   \n",
       "1   ham             But i haf enuff space got like 4 mb...   \n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...   \n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...   \n",
       "4   ham  All done, all handed in. Don't know if mega sh...   \n",
       "\n",
       "                    predicted  \n",
       "0                         ham  \n",
       "1                         ham  \n",
       "2                        spam  \n",
       "3                         ham  \n",
       "4  needs human classification  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Now that we have a function that returns labels instead of printing them, we can use it to create a new column in our test set\n",
    "\n",
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1025\n",
      "Incorrect: 89\n",
      "Accuracy: 0.9201077199281867\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "    \n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Doc prescribed me morphine cause the other pai...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want 2 get laid tonight? Want real Dogging loc...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ham</td>\n",
       "      <td>We know TAJ MAHAL as symbol of love. But the o...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>spam</td>\n",
       "      <td>Show ur colours! Euro 2004 2-4-1 Offer! Get an...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>spam</td>\n",
       "      <td>goldviking (29/M) is inviting you to be his fr...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ham</td>\n",
       "      <td>WE REGRET TO INFORM U THAT THE NHS HAS MADE A ...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ola would get back to you maybe not today but ...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>spam</td>\n",
       "      <td>1000's flirting NOW! Txt GIRL or BLOKE &amp; ur NA...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>ham</td>\n",
       "      <td>How was txting and driving</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>ham</td>\n",
       "      <td>Please da call me any mistake from my side sor...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dear Voucher Holder 2 claim your 1st class air...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol! Nah wasn't too bad thanks. Its good to b ...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hottest pics straight to your phone!! See me g...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ham</td>\n",
       "      <td>Your dad is back in ph?</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>ham</td>\n",
       "      <td>Que pases un buen tiempo or something like that</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ham</td>\n",
       "      <td>Miss call miss call khelate kintu opponenter m...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>ham</td>\n",
       "      <td>Which channel:-):-):):-).</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>spam</td>\n",
       "      <td>Get a FREE mobile video player FREE movie. To ...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>spam</td>\n",
       "      <td>TheMob&gt;Yo yo yo-Here comes a new selection of ...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>spam</td>\n",
       "      <td>Phony £350 award - Todays Voda numbers ending ...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ü collecting ur laptop then going to configure...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>spam</td>\n",
       "      <td>U’ve Bin Awarded £50 to Play 4 Instant Cash. C...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>ham</td>\n",
       "      <td>That way transport is less problematic than on...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am getting threats from your sales executive...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>ham</td>\n",
       "      <td>You stayin out of trouble stranger!!saw Dave t...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey mr  and I are going to the sea view and ha...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dont think you need yellow card for uk travel....</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes watching footie but worried we're going to...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi did u decide wot 2 get 4 his bday if not il...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>ham</td>\n",
       "      <td>A swt thought: \"Nver get tired of doing little...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>spam</td>\n",
       "      <td>u r subscribed 2 TEXTCOMP 250 wkly comp. 1st w...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>ham</td>\n",
       "      <td>He like not v shock leh. Cos telling shuhui is...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes see ya not on the dot</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>ham</td>\n",
       "      <td>Goodmorning,my grandfather expired..so am on l...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dont forget you can place as many FREE Request...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi mate its RV did u hav a nice hol just a mes...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>ham</td>\n",
       "      <td>Do you hide anythiing or keeping distance from me</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your weekly Cool-Mob tones are ready to downlo...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>spam</td>\n",
       "      <td>FREE camera phones with linerental from 4.49/m...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>spam</td>\n",
       "      <td>For the most sparkling shopping breaks from 45...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>spam</td>\n",
       "      <td>A link to your picture has been sent. You can ...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg:Feelin kinda lnly hope u like 2 keep m...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>spam</td>\n",
       "      <td>Wanna get laid 2nite? Want real Dogging locati...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ya but it cant display internal subs so i gott...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>ham</td>\n",
       "      <td>Jordan got voted out last nite!</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>ham</td>\n",
       "      <td>Am on a train back from northampton so i'm afr...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS  \\\n",
       "4      ham  All done, all handed in. Don't know if mega sh...   \n",
       "16     ham  Doc prescribed me morphine cause the other pai...   \n",
       "57    spam  Want 2 get laid tonight? Want real Dogging loc...   \n",
       "71     ham  We know TAJ MAHAL as symbol of love. But the o...   \n",
       "84    spam  Show ur colours! Euro 2004 2-4-1 Offer! Get an...   \n",
       "89    spam  goldviking (29/M) is inviting you to be his fr...   \n",
       "93     ham  WE REGRET TO INFORM U THAT THE NHS HAS MADE A ...   \n",
       "98     ham  Ola would get back to you maybe not today but ...   \n",
       "114   spam  Not heard from U4 a while. Call me now am here...   \n",
       "121   spam  1000's flirting NOW! Txt GIRL or BLOKE & ur NA...   \n",
       "130    ham                         How was txting and driving   \n",
       "134    ham  Please da call me any mistake from my side sor...   \n",
       "135   spam  More people are dogging in your area now. Call...   \n",
       "141   spam  Dear Voucher Holder 2 claim your 1st class air...   \n",
       "143    ham  Lol! Nah wasn't too bad thanks. Its good to b ...   \n",
       "152    ham                  Unlimited texts. Limited minutes.   \n",
       "159    ham                                       26th OF JULY   \n",
       "169   spam  Hottest pics straight to your phone!! See me g...   \n",
       "176    ham                            Your dad is back in ph?   \n",
       "185    ham  Yun ah.the ubi one say if ü wan call by tomorr...   \n",
       "193    ham    Que pases un buen tiempo or something like that   \n",
       "207    ham  Miss call miss call khelate kintu opponenter m...   \n",
       "247    ham                          Which channel:-):-):):-).   \n",
       "254   spam  Get a FREE mobile video player FREE movie. To ...   \n",
       "263   spam  TheMob>Yo yo yo-Here comes a new selection of ...   \n",
       "277   spam  Phony £350 award - Todays Voda numbers ending ...   \n",
       "284    ham                             Nokia phone is lovly..   \n",
       "289    ham  Ü collecting ur laptop then going to configure...   \n",
       "293    ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "302    ham                   No calls..messages..missed calls   \n",
       "...    ...                                                ...   \n",
       "733   spam  U’ve Bin Awarded £50 to Play 4 Instant Cash. C...   \n",
       "735    ham  That way transport is less problematic than on...   \n",
       "741   spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "754    ham  I am getting threats from your sales executive...   \n",
       "758    ham  You stayin out of trouble stranger!!saw Dave t...   \n",
       "777    ham  Hey mr  and I are going to the sea view and ha...   \n",
       "788    ham  Dont think you need yellow card for uk travel....   \n",
       "836    ham  Yes watching footie but worried we're going to...   \n",
       "849    ham  Hi did u decide wot 2 get 4 his bday if not il...   \n",
       "852    ham  A swt thought: \"Nver get tired of doing little...   \n",
       "862   spam  u r subscribed 2 TEXTCOMP 250 wkly comp. 1st w...   \n",
       "871    ham  He like not v shock leh. Cos telling shuhui is...   \n",
       "876   spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "882    ham                          Yes see ya not on the dot   \n",
       "885   spam                                      2/2 146tf150p   \n",
       "903    ham  Goodmorning,my grandfather expired..so am on l...   \n",
       "917   spam  Dont forget you can place as many FREE Request...   \n",
       "920    ham  Hi mate its RV did u hav a nice hol just a mes...   \n",
       "933    ham  Do you hide anythiing or keeping distance from me   \n",
       "944   spam  Your weekly Cool-Mob tones are ready to downlo...   \n",
       "953   spam  Hello. We need some posh birds and chaps to us...   \n",
       "964   spam  FREE camera phones with linerental from 4.49/m...   \n",
       "992   spam  For the most sparkling shopping breaks from 45...   \n",
       "1006  spam  A link to your picture has been sent. You can ...   \n",
       "1048  spam  FreeMsg:Feelin kinda lnly hope u like 2 keep m...   \n",
       "1055  spam  XXXMobileMovieClub: To use your credit, click ...   \n",
       "1059  spam  Wanna get laid 2nite? Want real Dogging locati...   \n",
       "1078   ham  Ya but it cant display internal subs so i gott...   \n",
       "1081   ham                    Jordan got voted out last nite!   \n",
       "1106   ham  Am on a train back from northampton so i'm afr...   \n",
       "\n",
       "                       predicted  \n",
       "4     needs human classification  \n",
       "16    needs human classification  \n",
       "57    needs human classification  \n",
       "71    needs human classification  \n",
       "84    needs human classification  \n",
       "89    needs human classification  \n",
       "93    needs human classification  \n",
       "98    needs human classification  \n",
       "114   needs human classification  \n",
       "121   needs human classification  \n",
       "130                         spam  \n",
       "134   needs human classification  \n",
       "135   needs human classification  \n",
       "141   needs human classification  \n",
       "143   needs human classification  \n",
       "152                         spam  \n",
       "159                         spam  \n",
       "169   needs human classification  \n",
       "176   needs human classification  \n",
       "185   needs human classification  \n",
       "193   needs human classification  \n",
       "207   needs human classification  \n",
       "247                         spam  \n",
       "254   needs human classification  \n",
       "263   needs human classification  \n",
       "277   needs human classification  \n",
       "284                         spam  \n",
       "289   needs human classification  \n",
       "293   needs human classification  \n",
       "302                         spam  \n",
       "...                          ...  \n",
       "733   needs human classification  \n",
       "735   needs human classification  \n",
       "741   needs human classification  \n",
       "754   needs human classification  \n",
       "758   needs human classification  \n",
       "777   needs human classification  \n",
       "788   needs human classification  \n",
       "836   needs human classification  \n",
       "849   needs human classification  \n",
       "852   needs human classification  \n",
       "862   needs human classification  \n",
       "871   needs human classification  \n",
       "876                          ham  \n",
       "882                         spam  \n",
       "885                          ham  \n",
       "903   needs human classification  \n",
       "917   needs human classification  \n",
       "920   needs human classification  \n",
       "933   needs human classification  \n",
       "944   needs human classification  \n",
       "953                          ham  \n",
       "964   needs human classification  \n",
       "992   needs human classification  \n",
       "1006  needs human classification  \n",
       "1048  needs human classification  \n",
       "1055  needs human classification  \n",
       "1059  needs human classification  \n",
       "1078  needs human classification  \n",
       "1081  needs human classification  \n",
       "1106  needs human classification  \n",
       "\n",
       "[89 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = []\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] != row['predicted']:\n",
    "        incorrect.append(row)\n",
    "        \n",
    "incor = pd.DataFrame(incorrect)\n",
    "incor.head(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter had an accuracy of 92% on the test set, which is a great result. The messages that were classified incorrect were difficult to classify might be due to inclusion of many new words out of the vocabulary or not having the complete message displayed in the SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
